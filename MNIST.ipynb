{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J01iVlEbmvt0",
        "outputId": "00bc0ed5-8a32-4554-b689-1e419eae1880"
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 12\n",
        "\n",
        "\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        fill_mode='nearest')\n",
        "\n",
        "\n",
        "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                    steps_per_epoch=x_train.shape[0] // batch_size,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    epochs=epochs, verbose=2)\n",
        "score = model.evaluate(x_test, y_test, verbose=2)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "\n",
        "model.save('model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:62: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "468/468 - 171s - loss: 1.1466 - accuracy: 0.6128 - val_loss: 0.1836 - val_accuracy: 0.9498 - 171s/epoch - 365ms/step\n",
            "Epoch 2/12\n",
            "468/468 - 196s - loss: 0.6064 - accuracy: 0.8079 - val_loss: 0.1223 - val_accuracy: 0.9630 - 196s/epoch - 419ms/step\n",
            "Epoch 3/12\n",
            "468/468 - 168s - loss: 0.4693 - accuracy: 0.8546 - val_loss: 0.0971 - val_accuracy: 0.9693 - 168s/epoch - 359ms/step\n",
            "Epoch 4/12\n",
            "468/468 - 163s - loss: 0.4061 - accuracy: 0.8751 - val_loss: 0.0963 - val_accuracy: 0.9689 - 163s/epoch - 349ms/step\n",
            "Epoch 5/12\n",
            "468/468 - 161s - loss: 0.3574 - accuracy: 0.8914 - val_loss: 0.0908 - val_accuracy: 0.9724 - 161s/epoch - 344ms/step\n",
            "Epoch 6/12\n",
            "468/468 - 161s - loss: 0.3270 - accuracy: 0.9009 - val_loss: 0.0909 - val_accuracy: 0.9730 - 161s/epoch - 344ms/step\n",
            "Epoch 7/12\n",
            "468/468 - 161s - loss: 0.3047 - accuracy: 0.9096 - val_loss: 0.0808 - val_accuracy: 0.9744 - 161s/epoch - 343ms/step\n",
            "Epoch 8/12\n",
            "468/468 - 160s - loss: 0.2891 - accuracy: 0.9137 - val_loss: 0.0640 - val_accuracy: 0.9804 - 160s/epoch - 341ms/step\n",
            "Epoch 9/12\n",
            "468/468 - 163s - loss: 0.2732 - accuracy: 0.9166 - val_loss: 0.0642 - val_accuracy: 0.9811 - 163s/epoch - 348ms/step\n",
            "Epoch 10/12\n",
            "468/468 - 162s - loss: 0.2585 - accuracy: 0.9208 - val_loss: 0.0662 - val_accuracy: 0.9792 - 162s/epoch - 346ms/step\n",
            "Epoch 11/12\n",
            "468/468 - 162s - loss: 0.2527 - accuracy: 0.9243 - val_loss: 0.0698 - val_accuracy: 0.9780 - 162s/epoch - 347ms/step\n",
            "Epoch 12/12\n",
            "468/468 - 164s - loss: 0.2408 - accuracy: 0.9291 - val_loss: 0.0660 - val_accuracy: 0.9786 - 164s/epoch - 350ms/step\n",
            "313/313 - 7s - loss: 0.0660 - accuracy: 0.9786 - 7s/epoch - 22ms/step\n",
            "Test loss: 0.0659782886505127\n",
            "Test accuracy: 0.978600025177002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdAl00wZm70x"
      },
      "source": [
        "import numpy as np\n",
        "import cv2 as cv\n",
        "from tensorflow.keras.models import load_model\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "img_color = cv.imread('/content/drive/MyDrive/crop/tt.jpg', cv.IMREAD_COLOR)\n",
        "img_gray = cv.cvtColor(img_color, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "\n",
        "ret,img_binary = cv.threshold(img_gray, 0, 255, cv.THRESH_BINARY_INV | cv.THRESH_OTSU)\n",
        "\n",
        "kernel = cv.getStructuringElement( cv.MORPH_RECT, ( 5, 5 ) )\n",
        "img_binary = cv.morphologyEx(img_binary, cv. MORPH_CLOSE, kernel)\n",
        "\n",
        "cv2_imshow(img_binary)\n",
        "\n",
        "contours, hierarchy = cv.findContours(img_binary, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "for contour in contours:\n",
        "\n",
        "    x, y, w, h = cv.boundingRect(contour)\n",
        "\n",
        "\n",
        "\n",
        "    length = max(w, h) + 60\n",
        "    img_digit = np.zeros((length, length, 1),np.uint8)\n",
        "\n",
        "    new_x,new_y = x-(length - w)//2, y-(length - h)//2\n",
        "\n",
        "\n",
        "    img_digit = img_binary[new_y:new_y+length, new_x:new_x+length]\n",
        "\n",
        "    kernel = np.ones((5, 5), np.uint8)\n",
        "    img_digit = cv.morphologyEx(img_digit, cv.MORPH_DILATE, kernel)\n",
        "\n",
        "    cv2_imshow(img_digit)\n",
        "\n",
        "    model = load_model('model.h5')\n",
        "\n",
        "    img_digit = cv.resize(img_digit, (28, 28), interpolation=cv.INTER_AREA)\n",
        "\n",
        "    img_digit = img_digit / 255.0\n",
        "\n",
        "    img_input = img_digit.reshape(1, 28, 28, 1)\n",
        "    predictions = model.predict(img_input)\n",
        "\n",
        "\n",
        "    number = np.argmax(predictions)\n",
        "    print(number)\n",
        "\n",
        "    cv.rectangle(img_color, (x, y), (x+w, y+h), (255, 255, 0), 1)\n",
        "\n",
        "\n",
        "    location = (x + int(w *0.5), y - 10)\n",
        "    font = cv.FONT_HERSHEY_COMPLEX\n",
        "    fontScale = 1.2\n",
        "    cv.putText(img_color, str(number), location, font, fontScale, (0,255,0), 2)\n",
        "\n",
        "\n",
        "cv2_imshow(img_color)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}